{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tools from previous assignement</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kively/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/kively/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "from nltk import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict, OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, col_names, skip_first_line=False): #converts the file to the pandas dataframe, skips the first line(default column names)\n",
    "    return pd.read_csv(filename, sep='\\t', header=None, names=col_names, skiprows=1 if skip_first_line else None)\n",
    "\n",
    "\n",
    "def preprocessing(data, flag_remove, flag_stem): #takes data as list of strings\n",
    "    \"\"\"\n",
    "    Preprocess the passages tokenizing each sentence, converting to lower case, excluding non alphabetic words\n",
    "    removing stopwords and stemming\n",
    "    \n",
    "    :param data:                list of strings (passages) \n",
    "    :param flag_remove:         True to remove stop words\n",
    "    :param flag_stem:           True to convert to stems\n",
    "    :return:                    a list of lists with the tokens of each passage\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stemmer = PorterStemmer()\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sentence in data:\n",
    "        # tokenize each sentence\n",
    "        try: \n",
    "            tokenized_sentence = tokenizer.tokenize(sentence)\n",
    "        except: \n",
    "            print(sentence)\n",
    "            return None\n",
    "        \n",
    "        # convert to lower case\n",
    "        sentence = [w.lower() for w in tokenized_sentence]\n",
    "\n",
    "        # exclude non alphabetic words\n",
    "        only_alpha_sentence = [word for word in sentence if word.isalpha()]\n",
    "        \n",
    "        # remove stop words\n",
    "        if flag_remove:\n",
    "            filtered_sentence = [w for w in only_alpha_sentence if w not in stop_words]\n",
    "        else:\n",
    "            filtered_sentence = only_alpha_sentence\n",
    "\n",
    "        tokenized_sentence = []\n",
    "\n",
    "        if flag_stem:\n",
    "            # stemming\n",
    "            for word in filtered_sentence:\n",
    "                tokenized_sentence.append(stemmer.stem(word))\n",
    "        else:\n",
    "            tokenized_sentence = filtered_sentence\n",
    "\n",
    "        processed_sentences.append(tokenized_sentence)\n",
    "   \n",
    "    return processed_sentences\n",
    "\n",
    "\n",
    "def build(input_file, add_relevancy=False, skip_first_line=False): \n",
    "    #query with relevance of passage (new dictionary)\n",
    "    #query id with query tokens(list) (dict), as in previous assignment\n",
    "    #passage id with passage tokens (dict), as in previous assignment \n",
    "    \"\"\"\n",
    "    Builds data structures based on a file that contains queries, passages and relevancy\n",
    "\n",
    "    :param input_file           the input file of the form\n",
    "                                    q_id, p_id, q_text, p_text, relevancy(optional)\n",
    "    :param add_relevancy        if True, append a column with relevancy\n",
    "    :param skip_first_line.     True if we have to skip first line\n",
    "    :return:                    3 dictionaries:\n",
    "                                1.  {\n",
    "                                        q_id: {\n",
    "                                            p_id: relevance,\n",
    "                                            ...\n",
    "                                        },\n",
    "                                        ...\n",
    "                                    }\n",
    "                                2.  {\n",
    "                                        q_id: clean list of query tokens,\n",
    "                                        ...\n",
    "                                    }\n",
    "                                3.  {\n",
    "                                        p_id: clean list of passage tokens,\n",
    "                                        ...\n",
    "                                    }\n",
    "    \"\"\"\n",
    "    if add_relevancy is None:\n",
    "        columns = ['q_id', 'p_id', 'q_text', 'p_text']\n",
    "    else:\n",
    "        columns = ['q_id', 'p_id', 'q_text', 'p_text', 'relevancy']\n",
    "\n",
    "    f = read_file(input_file, columns, skip_first_line=skip_first_line)\n",
    "    if add_relevancy:\n",
    "        relevancy = np.ones(len(f))\n",
    "        f['relevancy'] = relevancy\n",
    "\n",
    "    \n",
    "    # First create the relevacy dictionary\n",
    "    idx = set(np.nonzero((f.relevancy > 0.0).to_numpy())[0])  # These are the indices of relevant documents\n",
    "    group_by_query = f.groupby('q_id')\n",
    "    q_p = {}\n",
    "    for query_id, indices in group_by_query.groups.items():\n",
    "        _indices = list(idx & set(indices))\n",
    "        q_p[query_id] = dict(\n",
    "            zip(\n",
    "                f.p_id.iloc[_indices],\n",
    "                f.relevancy.iloc[_indices]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Create clean queries\n",
    "    q_c = dict(\n",
    "        (\n",
    "            query_id,\n",
    "            preprocessing(\n",
    "                [\n",
    "                    f.q_text.iloc[\n",
    "                        group_by_query.groups[query_id][0]\n",
    "                    ]\n",
    "                ], True, True)[0]\n",
    "        ) for query_id in group_by_query.groups.keys()\n",
    "    )\n",
    "\n",
    "    idx = [p.index[0] for _, p in f.groupby([\"p_id\"])]\n",
    "    unique_pids = list(f.p_id.iloc[idx])\n",
    "    tokens = list(f.p_text.iloc[idx])\n",
    "    tokens = preprocessing(tokens, True, True)\n",
    "    p_c = dict(zip(unique_pids, tokens))\n",
    "\n",
    "    return q_p, q_c, p_c\n",
    "\n",
    "\n",
    "def inv_idx(passages, filtered_pids=None): #from a dictionary, find the inverted index token\n",
    "    \"\"\"\n",
    "    Given a dict of passage id -> passage tokens, creates an inverted index from a selected set of passages.\n",
    "\n",
    "    :param passages:            dict passage id -> passage tokens (list)\n",
    "    :param filtered_pids:       set of passage ids to account for or None for all\n",
    "    :return:                    a dict with token -> dict { passage id -> frequency }\n",
    "    \"\"\"\n",
    "    if filtered_pids is None:\n",
    "        filtered_pids = passages.keys()\n",
    "\n",
    "    i_id = {}\n",
    "    for pid in filtered_pids:\n",
    "        token_position = 0\n",
    "        for token in passages[pid]:\n",
    "            if token not in i_id.keys():\n",
    "                i_id[token] = {pid: [token_position]}\n",
    "            else:\n",
    "                try:\n",
    "                    i_id[token][pid].append(token_position)\n",
    "                except KeyError:\n",
    "                    i_id[token][pid] = [token_position]\n",
    "            token_position += 1\n",
    "    return i_id\n",
    "\n",
    "\n",
    "\n",
    "def BM_25(\n",
    "    query,\n",
    "    p_id,\n",
    "    p_tokens,\n",
    "    inverted_index_dict,\n",
    "    av_len,\n",
    "    N,\n",
    "    k1=1.2,\n",
    "    k2=100,\n",
    "    b=0.75\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the BM25 score of a given query with a given passage\n",
    "    \n",
    "    :param query:               the query list of tokens\n",
    "    :param p_id:                the passage id (for use with inverted index)\n",
    "    :param p_tokens:            the passage list of tokens\n",
    "    :param inverted_index_dict: the inverted index of tokens\n",
    "    :param av_len:              average document length\n",
    "    :param N:                   the total number of passages\n",
    "    :param k1:                  the k1 parameter\n",
    "    :param k2:                  the k2 parameter\n",
    "    :param b:                   the b parameter\n",
    "    :return:                    the BM 25 score\n",
    "    \"\"\"\n",
    "    dl = len(p_tokens)\n",
    "    K = k1 * ((1 - b) + b * dl / av_len)\n",
    "    score = 0\n",
    "\n",
    "    for token in query:\n",
    "        try:\n",
    "            n_i = len(inverted_index_dict[token])\n",
    "        except KeyError:\n",
    "            # We are here because the query token does not exists in any passage\n",
    "            n_i = 0\n",
    "        # check whether qf is indeed 1\n",
    "        qf = 1 #assuming each token appears only once in the specific query\n",
    "        try:\n",
    "            f_i = len(inverted_index_dict[token][p_id])\n",
    "        except KeyError:\n",
    "            f_i = 0\n",
    "\n",
    "        score += np.log((N - n_i + 0.5) / (n_i + 0.5)) * (k1 + 1) * f_i / (K + f_i) * (k2 + 1) * qf / (k2 + qf)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Precision</h3>\n",
    "\n",
    "| |Relevant|Non-relevant|\n",
    "|-|--------|------------|\n",
    "|Retrieved|a|b|\n",
    "|Non-retrieved|c|||\n",
    "\n",
    "$$\n",
    "precision = \\frac{a}{a+b} \\;\\;,\\;\\; recall = \\frac{a}{a+c}\n",
    "$$\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "    Start with a=0, b=0, c=number of relevant documents\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for k in range(1, max rank + 1):\n",
    "        d = document with rank k\n",
    "        if d is relevant:\n",
    "            a += 1\n",
    "            c -= 1\n",
    "        else:\n",
    "            b += 1\n",
    "        precisions.append(a / (a + b))\n",
    "        recalls.append(a / (a + c))\n",
    "        \n",
    "Subtasks:\n",
    "\n",
    "- Read files, preprocess queries and passages, bulid inverted indexes and save them\n",
    "- Build an extra dict of the form: {query id: { passage_id: relevance, ...}, ...}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build data structures</h3>\n",
    "\n",
    "We use the flag __BUILD__. If it is True, then all data structures are initialized and are stored to files. If it is False, the necessary data structures are recoverd from files.\n",
    "\n",
    "    Estimated time when __BUILD__ == True: 4-5 hours\n",
    "    Estimated time when __BUILD__ == False: 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #serialisation (saves objects to files)\n",
    "\n",
    "__BUILD__ = False\n",
    "\n",
    "c_q_p = c_q_c = c_p_c = c_iid = t_q_p = t_q_c = t_p_c = t_iid = v_q_p = v_q_c = v_p_c = v_iid = {}\n",
    "\n",
    "if __BUILD__:\n",
    "    # Read first the candidate_passages_top1000.tsv\n",
    "    c_q_p, c_q_c, c_p_c = build(\"dataset/candidate_passages_top1000.tsv\", add_relevancy=True, skip_first_line=False)\n",
    "    c_iid = inv_idx(c_p_c)\n",
    "    with open('dataset/cpt_q_p.pickle', 'wb') as f:\n",
    "        pickle.dump(c_q_p, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/cpt_q_c.pickle', 'wb') as f:\n",
    "        pickle.dump(c_q_c, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/cpt_p_c.pickle', 'wb') as f:\n",
    "        pickle.dump(c_p_c, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/cpt_iid.pickle', 'wb') as f:\n",
    "        pickle.dump(c_iid, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "    # Read then the training data\n",
    "    t_q_p, t_q_c, t_p_c = build(\"dataset/train_data.tsv\", add_relevancy=False, skip_first_line=True)\n",
    "    t_iid = inv_idx(t_p_c)\n",
    "    with open('dataset/td_q_p.pickle', 'wb') as f:\n",
    "        pickle.dump(t_q_p, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/td_q_c.pickle', 'wb') as f:\n",
    "        pickle.dump(t_q_c, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/td_p_c.pickle', 'wb') as f:\n",
    "        pickle.dump(t_p_c, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/td_iid.pickle', 'wb') as f:\n",
    "        pickle.dump(t_iid, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Read finally the validation data\n",
    "    v_q_p, v_q_c, v_p_c = build(\"dataset/validation_data.tsv\", add_relevancy=False, skip_first_line=True)\n",
    "    v_iid = inv_idx(v_p_c)\n",
    "    with open('dataset/vd_q_p.pickle', 'wb') as f:\n",
    "        pickle.dump(v_q_p, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/vd_q_c.pickle', 'wb') as f:\n",
    "        pickle.dump(v_q_c, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/vd_p_c.pickle', 'wb') as f:\n",
    "        pickle.dump(v_p_c, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('dataset/vd_iid.pickle', 'wb') as f:\n",
    "        pickle.dump(v_iid, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('dataset/cpt_q_p.pickle', 'rb') as f:\n",
    "        c_q_p = pickle.load(f)\n",
    "    with open('dataset/cpt_q_c.pickle', 'rb') as f:\n",
    "        c_q_c = pickle.load(f)\n",
    "    with open('dataset/cpt_p_c.pickle', 'rb') as f:\n",
    "        c_p_c = pickle.load(f)\n",
    "    with open('dataset/cpt_iid.pickle', 'rb') as f:\n",
    "        c_iid = pickle.load(f)\n",
    "    with open('dataset/td_q_p.pickle', 'rb') as f:\n",
    "        t_q_p = pickle.load(f)\n",
    "    with open('dataset/td_q_c.pickle', 'rb') as f:\n",
    "        t_q_c = pickle.load(f)\n",
    "    with open('dataset/td_p_c.pickle', 'rb') as f:\n",
    "        t_p_c = pickle.load(f)\n",
    "    with open('dataset/td_iid.pickle', 'rb') as f:\n",
    "        t_iid = pickle.load(f)\n",
    "    with open('dataset/vd_q_p.pickle', 'rb') as f:\n",
    "        v_q_p = pickle.load(f)\n",
    "    with open('dataset/vd_q_c.pickle', 'rb') as f:\n",
    "        v_q_c = pickle.load(f)\n",
    "    with open('dataset/vd_p_c.pickle', 'rb') as f:\n",
    "        v_p_c = pickle.load(f)\n",
    "    with open('dataset/vd_iid.pickle', 'rb') as f:\n",
    "        v_iid = pickle.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_q_p\tc_q_c\tc_p_c\tc_iid\t\tt_q_p\tt_q_c\tt_p_c\tt_iid\t\tv_q_p\tv_q_c\tv_p_c\tv_iid\n",
      "200\t200\t182469\t88408\t\t4590\t4590\t2933768\t490021\t\t1148\t1148\t955211\t248520\n",
      "\n",
      "Queries from 1st set:\n",
      "q_id=507445\tq_tokens=['symptom', 'differ', 'type', 'brain', 'bleed']\n",
      "q_id=203318\tq_tokens=['hilton', 'lifetim', 'diamond', 'member', 'benefit']\n",
      "q_id=427578\tq_tokens=['titan', 'biggest', 'ship', 'ever']\n",
      "q_id=1037798\tq_tokens=['robert', 'gray']\n",
      "q_id=502261\tq_tokens=['stamford', 'feder', 'credit', 'union', 'rout', 'number']\n",
      "\n",
      "Queries from test set:\n",
      "q_id=997878\tq_tokens=['saukvil', 'wisconsin']\n",
      "q_id=814282\tq_tokens=['ddc']\n",
      "q_id=1092484\tq_tokens=['nigeria', 'read', 'newspap']\n",
      "q_id=226335\tq_tokens=['genom', 'edit', 'work']\n",
      "q_id=472359\tq_tokens=['pauld', 'oh', 'counti']\n",
      "\n",
      "Queries from validation set:\n",
      "q_id=147166\tq_tokens=['differ', 'elastom', 'polym']\n",
      "q_id=1010173\tq_tokens=['year', 'rubi', 'bridg', 'award', 'presidenti', 'medal', 'honor']\n",
      "q_id=1092665\tq_tokens=['minnesota', 'current', 'popul']\n",
      "q_id=959854\tq_tokens=['slash', 'burn', 'agricultur', 'use']\n",
      "q_id=1010173\tq_tokens=['year', 'rubi', 'bridg', 'award', 'presidenti', 'medal', 'honor']\n"
     ]
    }
   ],
   "source": [
    "print('c_q_p\\tc_q_c\\tc_p_c\\tc_iid\\t\\tt_q_p\\tt_q_c\\tt_p_c\\tt_iid\\t\\tv_q_p\\tv_q_c\\tv_p_c\\tv_iid')\n",
    "print(\n",
    "    '{}\\t{}\\t{}\\t{}\\t\\t{}\\t{}\\t{}\\t{}\\t\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
    "        len(c_q_p), len(c_q_c), len(c_p_c), len(c_iid),\n",
    "        len(t_q_p), len(t_q_c), len(t_p_c), len(t_iid),\n",
    "        len(v_q_p), len(v_q_c), len(v_p_c), len(v_iid)\n",
    "    )\n",
    ")\n",
    "\n",
    "import random\n",
    "# Print some random queries\n",
    "print('Queries from 1st set:')\n",
    "for j in range(5):\n",
    "    k, v = random.choice(list(c_q_c.items()))\n",
    "    print('q_id={}\\tq_tokens={}'.format(k, v))\n",
    "\n",
    "print('\\nQueries from test set:')\n",
    "for j in range(5):\n",
    "    k, v = random.choice(list(t_q_c.items()))\n",
    "    print('q_id={}\\tq_tokens={}'.format(k, v))\n",
    "\n",
    "print('\\nQueries from validation set:')\n",
    "for j in range(5):\n",
    "    k, v = random.choice(list(v_q_c.items()))\n",
    "    print('q_id={}\\tq_tokens={}'.format(k, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6096\n"
     ]
    }
   ],
   "source": [
    "rd = set([])\n",
    "for k, v in t_q_c.items():\n",
    "    rd = rd | set(v)\n",
    "print(len(rd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(docs, q_p, max_rank=100): #report the first 100 ranked relevant docs\n",
    "    #this function is called after having implemented a scoring algorithm such as BM25\n",
    "    #sorts a list of scored docs after implementing a ranking algorithm \n",
    "    \"\"\"\n",
    "    Calculates the precision of a query result.\n",
    "    \n",
    "    :param docs:                sorted list of query results (passage ids)\n",
    "    :param q_p:                 dictionary showing the relevancy of passages with the query\n",
    "    :param max_rank:            the rank of passage to stop\n",
    "    \"\"\"\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = len(q_p) #total number of relevant docs, it is retrieved from the q_p dictionary (associates each query with its relevant passages)\n",
    "    #relevant docs: known from the data (relevancy column)\n",
    "    precisions_recalls = np.zeros((max_rank, 2)) #2d matrix, one column is the precision, the other column is the recall\n",
    "    recalls = np.zeros(max_rank) #list \n",
    "    for k in range(min(max_rank, len(docs))): #stops at max_rank\n",
    "        doc = docs[k] #select the next document \n",
    "        if doc in q_p.keys(): #if document is relevant, increase a \n",
    "            a += 1 #a: relevant docs\n",
    "            c -= 1 #non retrieved documents, decrease the non retrieved docs\n",
    "        else:\n",
    "            b += 1 #if it non-relevant, increase b \n",
    "        precisions_recalls[k, :] = [a / (a + b), a / (a + c)] #append to the list of precisions the value a/(a+b) for the precision\n",
    "        \n",
    "    return precisions_recalls, precisions_recalls[:, 0].mean()\n",
    "#mean value of the first column (mean precision: this is what we will use)\n",
    "#for each doc, it computes a precision\n",
    "#so we take the mean value of these precision values\n",
    "#precision: one value for each doc \n",
    "\n",
    "def average_precision(q_results, q_p, max_rank=100):\n",
    "    #we dont use the recalls column from the matrix\n",
    "    #mean average precision: for all the queries takes the average \n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the average precision over a set of query results\n",
    "    \n",
    "    :param q_results:           a dict of the form \n",
    "                                {\n",
    "                                    query_id: ranked list of passage ids\n",
    "                                    ...\n",
    "                                }\n",
    "    :param q_p:                 a dict of the form\n",
    "                                {\n",
    "                                    query_id: {\n",
    "                                        passage_id: relevancy, \n",
    "                                        ...\n",
    "                                    }, \n",
    "                                    ...\n",
    "                                }\n",
    "    :param max_rank:            the rank of passage to stop\n",
    "    \"\"\"\n",
    "    av_precision = 0 \n",
    "    for q_id, p_list in q_results.items():\n",
    "        _, prec = precision(p_list, q_p[q_id], max_rank=max_rank)\n",
    "        av_precision += prec\n",
    "    return av_precision / len(q_results)\n",
    "\n",
    "\n",
    "\n",
    "def idcg(q_p, max_rank=100): #ideal dcg\n",
    "    #ideal ranking \n",
    "    #formula with ideal (given rank/order)\n",
    "    #only argument the q_p, query-passage association: we assume the ideal order, from the data that we are given\n",
    "    #the relevance we are given, which docs have score 1 and which have score 0\n",
    "    #for normalisation\n",
    "    #formula with ideal ranking\n",
    "    #takes the passages with rank 1 with the correct order \n",
    "    #for each query, the order of the passage \n",
    "    \"\"\"\n",
    "    Calculates the ideal DCG of a query.\n",
    "    \n",
    "    :param q_p:                 dictionary showing the relevancy of passages with the query\n",
    "    :param max_rank:            the rank of passage to stop\n",
    "    \"\"\"\n",
    "    sorted_relevancies = list(q_p.values())\n",
    "    sorted_relevancies.sort(reverse=True)\n",
    "    max_id = min(max_rank, len(sorted_relevancies))\n",
    "    relevancies = np.array(sorted_relevancies[:max_id])\n",
    "    si = (2 ** relevancies - 1) / np.log2(np.arange(2, 2 + max_id)) #?\n",
    "    return si.sum()\n",
    "\n",
    "\n",
    "def dcg(docs, q_p, max_rank=100):\n",
    "    #docs: the order we found from the ranking algorithm (e.g. the BM25)\n",
    "    \"\"\"\n",
    "    Calculates the DCG of a query result up to rank max_rank.\n",
    "    \n",
    "    :param docs:                sorted list of query results (passage ids)\n",
    "    :param q_p:                 dictionary showing the relevancy of passages with the query\n",
    "    :param max_rank:            the rank of passage to stop\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    for j in range(max_rank):\n",
    "        try:\n",
    "            result += (2 ** q_p[docs[j]] -1) / np.log2(j + 2)    #j+1 ?\n",
    "        except KeyError:  # passage is non-relevant\n",
    "            pass\n",
    "\n",
    "    return result\n",
    "#try except pass?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to (foweach query in a list):\n",
    "<ul>\n",
    "    <li>Find the BM25 score of each passage</li>\n",
    "    <li>Create a sorted (ranked) list of retrieved passages</li>\n",
    "    <li>Calculate the precision (average)</li>\n",
    "    <li>Calculate the dcg of each passage</li>\n",
    "</ul>\n",
    "Finally, we print averages over all tested queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working set: validate\n",
      "Number of passages: 955211\n",
      "Average passage length: 32.563168765853824\n"
     ]
    }
   ],
   "source": [
    "# First select the dataset\n",
    "set_prefix = {'candidate': 'c', 'train': 't', 'validate': 'v'}\n",
    "selection = 'validate'\n",
    "\n",
    "w_q_p = eval('{}_q_p'.format(set_prefix[selection]))\n",
    "w_q_c = eval('{}_q_c'.format(set_prefix[selection]))\n",
    "w_p_c = eval('{}_p_c'.format(set_prefix[selection]))\n",
    "w_iid = eval('{}_iid'.format(set_prefix[selection]))\n",
    "\n",
    "average_doc_len = np.mean([len(w_p_c[x]) for x in w_p_c.keys()]) #for BM25\n",
    "total_docs = len(w_p_c)\n",
    "\n",
    "print(\"Working set: {}\\nNumber of passages: {}\\nAverage passage length: {}\".format(selection, total_docs, average_doc_len))\n",
    "#implements the BM25 and creates a list of query and its 100 retrieved passages with their score\n",
    "    \n",
    "    \n",
    "    \n",
    "#BM25 implementation starts here?\n",
    "#for all the queries-> num_queries=len(w_q_p.keys())?\n",
    "    \n",
    "    \n",
    "# Then create a list of queries to account for\n",
    "# Set a number for queries to use\n",
    "num_queries = 5  #for how many queries to implement the BM25, change this 5 -> for all the queries \n",
    "# Select randomly num_queries from queries\n",
    "q_ = random.sample(w_q_p.keys(), num_queries) \n",
    "\n",
    "results = {}\n",
    "ranked_lists = {}\n",
    "for q_id in q_:\n",
    "    scores_bm25 = {}\n",
    "    \n",
    "    # Loop for every passage\n",
    "    for pid in w_p_c.keys():\n",
    "        # Calculate scores\n",
    "        scores_bm25[pid] = BM_25(\n",
    "            w_q_c[q_id],  # the query list of tokens\n",
    "            pid,  # the passage id\n",
    "            w_p_c[pid],  # the passage list of tokens\n",
    "            w_iid,  # the inverted index of tokens\n",
    "            average_doc_len,  # average document length\n",
    "            total_docs,  # the total number of passages\n",
    "            k1=1.2,  # the k1 parameter\n",
    "            k2=100,  # the k2 parameter\n",
    "            b=0.75  # the b parameter\n",
    "        )\n",
    "\n",
    "    # Sort scores by decreasing order\n",
    "    results[q_id] = sorted(scores_bm25.items(), key=lambda x: x[1], reverse=True)\n",
    "    ranked_lists[q_id] = [x[0] for x in results[q_id]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dictionary results contains the sorted lists of passages (ranked) for each query.\n",
    "\n",
    "We can calculate metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: 1088658, n_dcg: 0.5706417189553201\n",
      "query: 570023, n_dcg: 0.0\n",
      "query: 1087835, n_dcg: 0.6309297535714575\n",
      "query: 1090077, n_dcg: 0.0\n",
      "query: 1099530, n_dcg: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "for q_id, docs in ranked_lists.items():\n",
    "    _idcg = idcg(w_q_p[q_id], max_rank=100)\n",
    "    n_dcg = dcg(docs, w_q_p[q_id], max_rank=100) / _idcg\n",
    "    print('query: {}, n_dcg: {}'.format(q_id, n_dcg))\n",
    "    \n",
    "    \n",
    "    #ndcg for each query for its 100 retrieved passages?\n",
    "    #not a single average number as ndcg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027932353474450295\n"
     ]
    }
   ],
   "source": [
    "print(average_precision(ranked_lists, w_q_p, max_rank=100))\n",
    "#average apo to precision queries\n",
    "#average "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Subtask 2</h3>\n",
    "\n",
    "Build first the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kively/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "call_back = EpochLogger()\n",
    "# Train the model\n",
    "#we train it only for the passages \n",
    "#query is the info that the user gives \n",
    "#the aved info we have comes fromt the docs \n",
    "w2v_model = Word2Vec(\n",
    "    t_p_c.values(), \n",
    "    min_count=2, \n",
    "    workers=8, \n",
    "    callbacks=[call_back]\n",
    ")\n",
    "#t_p_c:or each passage has a list of tokens, t stands for the training set, could also give the validation p_c\n",
    "#min count: drop the words that appear only 2 times in the whole document collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert words to vectors. We have to do the following:\n",
    "\n",
    "- Foreach passage, calculate the word2vec embedding by averaging the vector representation of passage' words (vectors $p_i$).\n",
    "- Do the same for the queries (vectors $q_i$).\n",
    "- Create the vectors $x_j = (p_i, q_k)$ foreach $i,  k$ and $y_j$ the relevancy of query $q_i$ to passage $p_k$\n",
    "- Now select a batch size (b_s) and get b_s vectors $x$ and their corresponding $y$\n",
    "- Learn $\\theta$ for this batch\n",
    "- Continue for n_epoch times\n",
    "\n",
    "We begin with a random initialized vector $\\theta$. We perform batch learning as follows:\n",
    "\n",
    "- Take a nember of queries ($n_q$) and a number of passages ($n_p$). Create the $n_q \\times n_p$ $x$ vectors and the corresponding $y$.\n",
    "- Laarn (adjust $\\theta$) from this batch\n",
    "- repeat the above procedure $n_e$ times (number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def create_embedding(model, token_list):\n",
    "    v = []\n",
    "    for token in token_list:\n",
    "        try:\n",
    "            v.append(model.wv[token])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if v == []:\n",
    "        raise ValueError\n",
    "    v = np.array(v).reshape((-1, 100))\n",
    "    return v.mean(axis=0)\n",
    "\n",
    "\n",
    "def create_emb_from_dict(d_c, w2v_model, normalize=True):\n",
    "    _emb = []\n",
    "    _ids = []\n",
    "    _i_ids = {}\n",
    "    j = 0\n",
    "    for _id, _tokens in d_c.items():\n",
    "        try:\n",
    "            aux = create_embedding(w2v_model, _tokens)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        _emb.append(aux / np.linalg.norm(aux) if normalize else aux)\n",
    "        _ids.append(_id)\n",
    "        _i_ids[_id] = j\n",
    "        j += 1\n",
    "    return np.array(_emb), np.array(_ids), _i_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for passages\n",
    "p_t_emb, p_t_ids, p_t_i_ids = create_emb_from_dict(t_p_c, w2v_model, normalize=True) #normalise=true ?\n",
    "q_t_emb, q_t_ids, q_t_i_ids = create_emb_from_dict(t_q_c, w2v_model, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2933762, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_t_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_t_emb_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c9a0c6a0b11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mq_t_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_t_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_t_emb_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_t_emb_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_t_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_t_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_t_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_t_emb_array' is not defined"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    p_t_emb_array = np.vstack(list(p_t_emb.values()))\n",
    "    p_t_ids = np.array(list(p_t_emb.keys()))\n",
    "    q_t_emb_array = np.vstack(list(q_t_emb.values()))\n",
    "    q_t_ids = np.array(list(q_t_emb.keys()))\n",
    "\n",
    "x = np.dot(q_t_emb_array, p_t_emb_array.T)\n",
    "s.shape\n",
    "print(p_t_ids.shape[0], np.min(p_t_ids), np.max(p_t_ids))\n",
    "print(q_t_ids.shape[0], np.min(q_t_ids), np.max(q_t_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8970921a8bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_t_emb\u001b[0m  \u001b[0;31m# dict(random.sample(q_t_emb.items(), n_q))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Select passages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpassages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_t_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Build vectors x, y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "alpha = 1E-3\n",
    "number_of_epochs = 10\n",
    "\n",
    "theta = np.random.rand(2, 1)  # np.random.rand(201, 1)  # the dimension of a x-vector is 200 + 1 for the constant\n",
    "\n",
    "for j in range(number_of_epochs):\n",
    "    # Select queries\n",
    "    queries = q_t_emb  # dict(random.sample(q_t_emb.items(), n_q))\n",
    "    # Select passages\n",
    "    passages = dict(random.sample(p_t_emb.items(), n_p))\n",
    "    \n",
    "    # Build vectors x, y\n",
    "    x = np.ones((n_q * n_p, 2))  # np.ones((n_q * n_p, 201))\n",
    "    y = np.zeros((n_q * n_p, 1))\n",
    "    current_index = 0\n",
    "    for q_id, v1 in queries.items():        \n",
    "        for p_id, v2 in passages.items():\n",
    "            try:\n",
    "                x[current_index, 1] = np.dot(v1.T, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)) # np.hstack((v1.flatten(), v2.flatten()))\n",
    "            except Exception as e:\n",
    "                print(e, v1.shape, v2.shape)\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                y[current_index] = t_q_p[q_id][p_id]\n",
    "            except KeyError:\n",
    "                y[current_index] = 0\n",
    "            current_index += 1\n",
    "\n",
    "    # Calculate error\n",
    "    e = y - g(np.dot(x, theta))\n",
    "    theta -= alpha * np.dot(x.T, e)\n",
    "    # print(theta)\n",
    "    if j % 10 == 0:\n",
    "        print('Epoch {}\\tMAE={:.6f}'.format(j, np.abs(e).mean()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our system (the vector $\\theta$) we can produce results from the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for all passages\n",
    "# Use data set\n",
    "if True:\n",
    "    q_w_emb = q_t_emb\n",
    "    p_w_emb = p_t_emb\n",
    "else:\n",
    "    num_passages = len(v_p_c)\n",
    "    p_v_emb = {}\n",
    "    for p_id, p_tokens in v_p_c.items():\n",
    "        try:\n",
    "            aux = create_embedding(w2v_model, p_tokens)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # Just for debug\n",
    "        if aux.shape[-1] != 100:\n",
    "            print(aux.shape)\n",
    "            break\n",
    "\n",
    "        p_v_emb[p_id] = aux\n",
    "\n",
    "    num_queries = len(v_q_c)\n",
    "    q_v_emb = {}\n",
    "    for q_id, q_tokens in v_q_c.items():\n",
    "        try:\n",
    "            aux = create_embedding(w2v_model, q_tokens)\n",
    "        except ValueError:\n",
    "            print(\"Excluding query with id: {}\".format(q_id))\n",
    "            continue\n",
    "\n",
    "        # Just for debug\n",
    "        if aux.shape[-1] != 100:\n",
    "            print(aux.shape)\n",
    "            break\n",
    "\n",
    "        q_v_emb[q_id] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2933762, 100)\n"
     ]
    }
   ],
   "source": [
    "# Create the passage score plus the constant value\n",
    "p_emb_array = np.vstack(list(p_w_emb.values()))\n",
    "p_ids = np.array(list(p_w_emb.keys()))\n",
    "print(p_emb_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.71308482e-24 1.47719746e-24 1.37793746e-24 1.20129047e-24\n",
      " 1.17498814e-24 1.16755821e-24 1.15669933e-24 1.12172445e-24\n",
      " 1.11381008e-24 1.11381008e-24]\n"
     ]
    }
   ],
   "source": [
    "# Select a number of queries\n",
    "queries = dict(random.sample(list(q_w_emb.items()), 1))\n",
    "\n",
    "# Foreach query, create a ranked list of passages\n",
    "result = {}\n",
    "for q_id, v1 in queries.items():\n",
    "    x = np.dot(p_emb_array, v1.reshape((-1, 1)))\n",
    "    q_score_ = theta[0] + theta[1] * x.flatten()\n",
    "    q_score = g(q_score_)\n",
    "    idx = np.argsort(q_score).flatten()[::-1]\n",
    "    result[q_id] = p_ids[idx]\n",
    "        \n",
    "print(q_score[idx][:10])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "p = average_precision(result, w_q_p, max_rank=200)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3902843, 7295912, 5226015,  897942, 7963658, 7587526, 1858427,\n",
       "       3767910, 3272633, 7733004, 7757748, 6462247, 3769517, 6462245,\n",
       "         43257, 1858426, 7857391, 1858428, 3828284, 3666078, 2444109,\n",
       "       3769513, 5480260, 1471108,  361843, 5432231, 7959686,  678784,\n",
       "       1858430,  727087, 5210356, 1858423, 1858431, 2374911, 5544541,\n",
       "        837207,  121115, 1839323, 6208518,  121114, 5480262, 3525242,\n",
       "       6897758, 8613511, 3514872,  121113, 2746339, 6836593, 2057007,\n",
       "       5868637, 8311226,  789533, 8311225, 1650937, 5544540, 3714735,\n",
       "       2043729, 1891232, 6933497, 5210357, 4663289, 2043731, 1026264,\n",
       "       3525241, 2043733, 4476636, 2095333, 2289275, 1471107,  127676,\n",
       "       2301205, 7628535, 2099814, 1566675, 6486773,  235940,  905344,\n",
       "       6897752, 7586250, 4782671, 8670644, 4671898, 5775133, 3206256,\n",
       "        789530, 2128932, 3938180, 6933501, 2095336,   13157, 7113345,\n",
       "       6462251,  160342, 7700360, 4838104, 3714734, 5134667, 2679445,\n",
       "       7069756,  273787])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_id = list(result.keys())[0]\n",
    "result[q_id][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7543541: 1.0}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_q_p[q_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
